---
layout: post
title: 【Denoising】Noise Basis Learning-for-Image Denoising-with-Subspace Projection
---

- **Paper** : [NBNet: Noise Basis Learning for Image Denoising with Subspace Projection](https://arxiv.org/abs/2012.15028)
- **Tags** : Image Denoising
- **Faculty** : Megvii Technology, Kuaishou Technology, UESTC
- **What I think** : 
- **Project / Code** : [NBNet](https://github.com/pminhtam/NBNet)



---

---


# 1.  Abstract, Introduction

- 通过学习图像的子空间投影来分离signal和noise，具体操作如下：

![image-20210415165433596](https://gitee.com/house_lee/PicGo/raw/master/20210415165440.png)

- 提出Subspace Attention Module (SSA) 来学习子空间投影
- 提出NBNet，一种基于UNet，带有SSA模块的网络
- 对基于投影的图像去噪方法进行了深入分析

---

# 2. Method

- 网络框架：

  ![image-20210416104303100](https://gitee.com/house_lee/PicGo/raw/master/20210416104303.png)

最主要的两个步骤是SSA模块中的 basis generation 和 projection，
basis generation: 从feature map中生成子空间基向量，通过concat两个输入后，reshape成$H \cdot W \times K$，其中$K$是可调参数。
projection: 将feature map转变成signal subspace，给定矩阵 $\mathit{V} \in \mathbb{R}^{N \times K}$，其中$N = H \cdot W$，让$\mathit{P}:\mathbb{R}^{N} \rightarrow \mathcal{V}$为信号子空间的正交投影矩阵，即

$
\mathit{P} = \mathit{V}(\mathit{V}^{\intercal}\mathit{V})^{-1}\mathit{V}^{\intercal}
$

其中$(\mathit{V}^{\intercal}\mathit{V})^{-1}$为归一化正则项，确保基向量正交化。

最后最后feature map $\mathit{X}$ 可以在信号子空间中重构为 $Y$，即 $Y = PX_{1}$

代码实现：

```python
class SSA(nn.Module):
    def __init__(self, in_channel, strides=1):
        super(SSA, self).__init__()

        self.conv1 = nn.Conv2d(in_channel, 16, kernel_size=3, stride=strides, padding=1)
        self.relu1 = nn.LeakyReLU(inplace=True)
        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=strides, padding=1)
        self.relu2 = nn.LeakyReLU(inplace=True)

        self.conv11 = nn.Conv2d(in_channel, 16, kernel_size=1, stride=strides, padding=0)

    def forward(self, input1, input2):
        input1 = input1.permute(0, 2, 3, 1)
        input2 = input2.permute(0, 2, 3, 1)
        cat = torch.cat([input1, input2], 3)
        cat = cat.permute(0, 3, 1, 2)
        out1 = self.relu1(self.conv1(cat))
        out1 = self.relu2(self.conv2(out1))
        out2 = self.conv11(cat)
        conv = (out1 + out2).permute(0, 2, 3, 1)
        H, W, K, batch_size = conv.shape[1], conv.shape[2], conv.shape[3],conv.shape[0]
        V = conv.reshape(batch_size,H * W, K)
        Vtrans = torch.transpose(V, 2, 1)
        Vinverse = torch.inverse(torch.bmm(Vtrans, V))
        Projection = torch.bmm(torch.bmm(V, Vinverse), Vtrans)
        H1, W1, C1,batch_size = input1.shape[1], input1.shape[2], input1.shape[3], input1.shape[0]
        X1 = input1.reshape(batch_size, H1 * W1, C1)
        Yproj = torch.bmm(Projection, X1)
        Y = Yproj.reshape(batch_size, H1, W1, C1)
        Y = Y.permute(0, 3, 1, 2)
        return Y
```

另外 loss 使用了 $L_1$ Loss。

---

# 3. Experiments

- 



---

# 4. Results

- ![image-20210416220600439](https://gitee.com/house_lee/PicGo/raw/master/20210416220600.png)
- ![image-20210416220614233](https://gitee.com/house_lee/PicGo/raw/master/20210416220614.png)



---
